The above scripts were designed with the purpose of normalizing an edition of the Venetus A scholia according to their individual lemmata (i.e. the dictionary forms of words), as opposed to the forms that appear in the actual manuscript. Typically this stage of normalization will occur after paleographic and orthographic normalizations.

There are three scripts required for this normalization. They should be used in the following order:

1.  [1Parsing.sc](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Scripts/creatingMNormalizedText/1Parsing.sc)
2.  [2creatingIndexOfParses.sc](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Scripts/creatingMNormalizedText/2creatingIndexOfParses.sc)
3.  [3assemblingParsedText.sc](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Scripts/creatingMNormalizedText/3assemblingParsedText.sc)

The first script, [1Parsing.sc](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Scripts/creatingMNormalizedText/1Parsing.sc), only requires one input. That input is some 2-column version of a Greek text, wherein the first column contains that CTS URN identifiers of the text and the second column contains the text intended to be normalized. For this thesis, I used this script to normalize the o-normalized version of the text found [here](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/VersionsOfScholia/o-normalized.tsv). The purpose of this script is to send each of the Greek words within the text of interest through the Morpheus morphological parser. The result, then, is the creation of a two-column file wherein the first column contains a word that was analyzed through the Morpheus parser and the second column contains the complete morphological analysis by the Morpheus parser. An example of the result of this script can be found [here](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Data/morpheusReplies.tsv).

The second script, [2creatingIndexOfParses.sc](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Scripts/creatingMNormalizedText/2creatingIndexOfParses.sc), only requires input, which is the two-column file that results from the previous script listed above. The purpose of this script is to simplify the dense morphological analysis that the Morpheus parser creates to only include part-of-speech and the possible lemmata. This script results in a three-column .tsv file with the first column containing the word which was analyzed. The second column contains the parts of speech that this word could be identified as, and the third column contains all the possibile lemmata for each given word. When there are more than one possible lemma, the parts of speech and lemmata are concatenated together and separated by an underscore. So, for example, the Greek word ἴσας could either be from the adjective for "equal" (ἴσος) or from the verb "to know" (οἶδα). So the row in the final table containing ἴσας would look like:

Word to be analyzed | Part of Speech | Lemma
---|---|---
ἴσας|adjective_verb_|ἴσος_οἶδα

The above table is precisely the format of the product of this script, and a more complete index of parses for all the words in my dataset of the Venetus A scholia can be found [here](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Data/indexOfLemmata.tsv).

The third and final script, [3assemblingParsedText.sc](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Scripts/creatingMNormalizedText/3assemblingParsedText.sc), required for the creation of an m-normalized version of the Venetus A scholia involves aligning the text of interest with the index of morphological parses created by the previous step in order to globally substitute words for their lemmata. The script requires two inputs. The first is the file containing the text to be normalized formatted with two columns, with the first column containing CTS URNs for the text, and the second column containing the text itself. This first input should be the same input as the text that was used as the input for the first script. So in the present example, I would re-use the o-normalized version of the text found [here](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/VersionsOfScholia/o-normalized.tsv). The second input is simply the three-columned index of morphological parses that was created by the previous script, wherein the first column contains the word analyzed by the Morpheus parser, the second column contains the parts of the speech the word could be recognized as, and the third contains the possible lemmata of the word as determined by Morpheus. Again, the full index based on my dataset of the Venetus A scholia can be found [here](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/Chapter2/Data/indexOfLemmata.tsv). The result of this script is another version of the text, p-normalized, which is identical in format to the text that was used as the input. So it will contain two columns where the first column contains the CTS URN for a scholion and the second column contains the text of the scholion but with every word replaced with its lemma or lemmata. The full p-normalized version of the dataset can be found [here](https://github.com/cjschu17/Thesis2016-2017/blob/master/Appendix/VersionsOfScholia/p-normalized.tsv).
